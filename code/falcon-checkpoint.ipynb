{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de49fe31-e59a-46d4-9445-a74d5735405b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T04:08:49.134402Z",
     "iopub.status.busy": "2023-07-26T04:08:49.133582Z",
     "iopub.status.idle": "2023-07-26T04:09:01.432777Z",
     "shell.execute_reply": "2023-07-26T04:09:01.432017Z",
     "shell.execute_reply.started": "2023-07-26T04:08:49.134380Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cpu:\n",
      "Collecting git+https://github.com/huggingface/transformers.git\n",
      "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-s8qb8t71\n",
      "  Running command git clone --filter=blob:none -q https://github.com/huggingface/transformers.git /tmp/pip-req-build-s8qb8t71\n",
      "  Resolved https://github.com/huggingface/transformers.git to commit a5cc30d72ae2dc19af534e4b35c986cc28db1275\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/pytorch/lib/python3.8/site-packages (from transformers==4.32.0.dev0) (2.31.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/pytorch/lib/python3.8/site-packages (from transformers==4.32.0.dev0) (2023.6.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/pytorch/lib/python3.8/site-packages (from transformers==4.32.0.dev0) (0.3.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/pytorch/lib/python3.8/site-packages (from transformers==4.32.0.dev0) (0.13.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/pytorch/lib/python3.8/site-packages (from transformers==4.32.0.dev0) (1.21.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/pytorch/lib/python3.8/site-packages (from transformers==4.32.0.dev0) (0.16.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/pytorch/lib/python3.8/site-packages (from transformers==4.32.0.dev0) (5.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/pytorch/lib/python3.8/site-packages (from transformers==4.32.0.dev0) (4.65.0)\n",
      "Requirement already satisfied: filelock in /opt/pytorch/lib/python3.8/site-packages (from transformers==4.32.0.dev0) (3.12.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/pytorch/lib/python3.8/site-packages (from transformers==4.32.0.dev0) (23.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/pytorch/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.32.0.dev0) (4.7.1)\n",
      "Requirement already satisfied: fsspec in /opt/pytorch/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.32.0.dev0) (2023.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/pytorch/lib/python3.8/site-packages (from requests->transformers==4.32.0.dev0) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/pytorch/lib/python3.8/site-packages (from requests->transformers==4.32.0.dev0) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/pytorch/lib/python3.8/site-packages (from requests->transformers==4.32.0.dev0) (2023.5.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/pytorch/lib/python3.8/site-packages (from requests->transformers==4.32.0.dev0) (1.26.16)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/huggingface/transformers.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c01d979c-bba2-4c0f-adbc-8f2ddd7f56cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T04:09:01.434389Z",
     "iopub.status.busy": "2023-07-26T04:09:01.434113Z",
     "iopub.status.idle": "2023-07-26T04:09:06.739896Z",
     "shell.execute_reply": "2023-07-26T04:09:06.739127Z",
     "shell.execute_reply.started": "2023-07-26T04:09:01.434368Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cpu:\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
      "     |████████████████████████████████| 34.5 MB 9.9 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: numpy<1.27.0,>=1.19.5 in /opt/pytorch/lib/python3.8/site-packages (from scipy) (1.21.6)\n",
      "Installing collected packages: scipy\n",
      "Successfully installed scipy-1.10.1\n"
     ]
    }
   ],
   "source": [
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "351a7f89-2cca-43cc-9e71-7b66ac45c820",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T04:09:06.741448Z",
     "iopub.status.busy": "2023-07-26T04:09:06.740965Z",
     "iopub.status.idle": "2023-07-26T04:09:15.538330Z",
     "shell.execute_reply": "2023-07-26T04:09:15.537537Z",
     "shell.execute_reply.started": "2023-07-26T04:09:06.741421Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cpu:\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.0.242-py3-none-any.whl (1.4 MB)\n",
      "     |████████████████████████████████| 1.4 MB 8.4 MB/s            \n",
      "\u001b[?25hCollecting langsmith<0.1.0,>=0.0.11\n",
      "  Downloading langsmith-0.0.14-py3-none-any.whl (29 kB)\n",
      "Collecting numexpr<3.0.0,>=2.8.4\n",
      "  Downloading numexpr-2.8.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (381 kB)\n",
      "     |████████████████████████████████| 381 kB 91.3 MB/s            \n",
      "\u001b[?25hCollecting tenacity<9.0.0,>=8.1.0\n",
      "  Downloading tenacity-8.2.2-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /opt/pytorch/lib/python3.8/site-packages (from langchain) (5.4.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/pytorch/lib/python3.8/site-packages (from langchain) (1.4.48)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/pytorch/lib/python3.8/site-packages (from langchain) (1.21.6)\n",
      "Collecting openapi-schema-pydantic<2.0,>=1.2\n",
      "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
      "     |████████████████████████████████| 90 kB 37.6 MB/s             \n",
      "\u001b[?25hCollecting aiohttp<4.0.0,>=3.8.3\n",
      "  Downloading aiohttp-3.8.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "     |████████████████████████████████| 1.1 MB 79.1 MB/s            \n",
      "\u001b[?25hCollecting dataclasses-json<0.6.0,>=0.5.7\n",
      "  Downloading dataclasses_json-0.5.13-py3-none-any.whl (26 kB)\n",
      "Collecting pydantic<2,>=1\n",
      "  Downloading pydantic-1.10.12-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "     |████████████████████████████████| 3.2 MB 108.1 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /opt/pytorch/lib/python3.8/site-packages (from langchain) (2.31.0)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.4.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (220 kB)\n",
      "     |████████████████████████████████| 220 kB 123.3 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/pytorch/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.1.0)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.9.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (266 kB)\n",
      "     |████████████████████████████████| 266 kB 125.2 MB/s            \n",
      "\u001b[?25hCollecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/pytorch/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (121 kB)\n",
      "     |████████████████████████████████| 121 kB 137.3 MB/s            \n",
      "\u001b[?25hCollecting marshmallow<4.0.0,>=3.18.0\n",
      "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
      "     |████████████████████████████████| 49 kB 28.6 MB/s             \n",
      "\u001b[?25hCollecting typing-inspect<1,>=0.4.0\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/pytorch/lib/python3.8/site-packages (from pydantic<2,>=1->langchain) (4.7.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/pytorch/lib/python3.8/site-packages (from requests<3,>=2->langchain) (1.26.16)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/pytorch/lib/python3.8/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/pytorch/lib/python3.8/site-packages (from requests<3,>=2->langchain) (2023.5.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/pytorch/lib/python3.8/site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
      "Requirement already satisfied: packaging>=17.0 in /opt/pytorch/lib/python3.8/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
      "Collecting mypy-extensions>=0.3.0\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: mypy-extensions, multidict, frozenlist, yarl, typing-inspect, pydantic, marshmallow, async-timeout, aiosignal, tenacity, openapi-schema-pydantic, numexpr, langsmith, dataclasses-json, aiohttp, langchain\n",
      "Successfully installed aiohttp-3.8.5 aiosignal-1.3.1 async-timeout-4.0.2 dataclasses-json-0.5.13 frozenlist-1.4.0 langchain-0.0.242 langsmith-0.0.14 marshmallow-3.20.1 multidict-6.0.4 mypy-extensions-1.0.0 numexpr-2.8.4 openapi-schema-pydantic-1.2.4 pydantic-1.10.12 tenacity-8.2.2 typing-inspect-0.9.0 yarl-1.9.2\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ced2d734-5c91-4f72-93ac-3f64805672c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T04:09:15.540570Z",
     "iopub.status.busy": "2023-07-26T04:09:15.540032Z",
     "iopub.status.idle": "2023-07-26T04:09:18.036105Z",
     "shell.execute_reply": "2023-07-26T04:09:18.035318Z",
     "shell.execute_reply.started": "2023-07-26T04:09:15.540549Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cpu:\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.99-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "     |████████████████████████████████| 1.3 MB 8.6 MB/s            \n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.99\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f4cc07e-4742-4c65-9251-be23ba14ee8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-20T03:33:14.243523Z",
     "iopub.status.busy": "2023-07-20T03:33:14.243354Z",
     "iopub.status.idle": "2023-07-20T03:33:18.847332Z",
     "shell.execute_reply": "2023-07-20T03:33:18.846506Z",
     "shell.execute_reply.started": "2023-07-20T03:33:14.243504Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.40.2-py3-none-any.whl (92.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.5/92.5 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.40.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb5a1d86-8279-4e45-85be-181378d428e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T04:09:18.037192Z",
     "iopub.status.busy": "2023-07-26T04:09:18.037006Z",
     "iopub.status.idle": "2023-07-26T04:09:20.568486Z",
     "shell.execute_reply": "2023-07-26T04:09:20.567732Z",
     "shell.execute_reply.started": "2023-07-26T04:09:18.037172Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cpu:\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n",
      "     |████████████████████████████████| 244 kB 9.8 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /opt/pytorch/lib/python3.8/site-packages (from accelerate) (5.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/pytorch/lib/python3.8/site-packages (from accelerate) (1.21.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/pytorch/lib/python3.8/site-packages (from accelerate) (23.1)\n",
      "Requirement already satisfied: psutil in /opt/pytorch/lib/python3.8/site-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/pytorch/lib/python3.8/site-packages (from accelerate) (2.0.1+cpu)\n",
      "Requirement already satisfied: networkx in /opt/pytorch/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/pytorch/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (4.7.1)\n",
      "Requirement already satisfied: filelock in /opt/pytorch/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (3.12.2)\n",
      "Requirement already satisfied: sympy in /opt/pytorch/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: jinja2 in /opt/pytorch/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/pytorch/lib/python3.8/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/pytorch/lib/python3.8/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-0.21.0\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7866876-2c0c-4465-a54c-6e6d2a3c0168",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T04:09:20.569644Z",
     "iopub.status.busy": "2023-07-26T04:09:20.569464Z",
     "iopub.status.idle": "2023-07-26T04:09:28.312196Z",
     "shell.execute_reply": "2023-07-26T04:09:28.311482Z",
     "shell.execute_reply.started": "2023-07-26T04:09:20.569625Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cpu:\n",
      "Collecting xformers\n",
      "  Downloading xformers-0.0.20-cp38-cp38-manylinux2014_x86_64.whl (109.1 MB)\n",
      "     |████████████████████████████████| 109.1 MB 102 kB/s            \n",
      "\u001b[?25hCollecting pyre-extensions==0.0.29\n",
      "  Downloading pyre_extensions-0.0.29-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: numpy in /opt/pytorch/lib/python3.8/site-packages (from xformers) (1.21.6)\n",
      "Requirement already satisfied: torch==2.0.1 in /opt/pytorch/lib/python3.8/site-packages (from xformers) (2.0.1+cpu)\n",
      "Requirement already satisfied: typing-inspect in /opt/pytorch/lib/python3.8/site-packages (from pyre-extensions==0.0.29->xformers) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/pytorch/lib/python3.8/site-packages (from pyre-extensions==0.0.29->xformers) (4.7.1)\n",
      "Requirement already satisfied: networkx in /opt/pytorch/lib/python3.8/site-packages (from torch==2.0.1->xformers) (3.1)\n",
      "Requirement already satisfied: sympy in /opt/pytorch/lib/python3.8/site-packages (from torch==2.0.1->xformers) (1.12)\n",
      "Requirement already satisfied: jinja2 in /opt/pytorch/lib/python3.8/site-packages (from torch==2.0.1->xformers) (3.1.2)\n",
      "Requirement already satisfied: filelock in /opt/pytorch/lib/python3.8/site-packages (from torch==2.0.1->xformers) (3.12.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/pytorch/lib/python3.8/site-packages (from jinja2->torch==2.0.1->xformers) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/pytorch/lib/python3.8/site-packages (from sympy->torch==2.0.1->xformers) (1.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/pytorch/lib/python3.8/site-packages (from typing-inspect->pyre-extensions==0.0.29->xformers) (1.0.0)\n",
      "Installing collected packages: pyre-extensions, xformers\n",
      "Successfully installed pyre-extensions-0.0.29 xformers-0.0.20\n"
     ]
    }
   ],
   "source": [
    "! pip install xformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b80c854f-538b-4f62-a438-2cec9ebaf2ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T04:09:28.313432Z",
     "iopub.status.busy": "2023-07-26T04:09:28.313233Z",
     "iopub.status.idle": "2023-07-26T04:09:30.652088Z",
     "shell.execute_reply": "2023-07-26T04:09:30.651307Z",
     "shell.execute_reply.started": "2023-07-26T04:09:28.313404Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'sentencepiece'...\n",
      "remote: Enumerating objects: 4815, done.\u001b[K\n",
      "remote: Counting objects: 100% (1478/1478), done.\u001b[K\n",
      "remote: Compressing objects: 100% (322/322), done.\u001b[K\n",
      "remote: Total 4815 (delta 1202), reused 1221 (delta 1116), pack-reused 3337\u001b[K\n",
      "Receiving objects: 100% (4815/4815), 26.73 MiB | 25.56 MiB/s, done.\n",
      "Resolving deltas: 100% (3311/3311), done.\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece\n",
    "!git clone https://github.com/google/sentencepiece.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfeebf1e-8874-4c57-9eb8-21f99745e9e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T04:15:00.056329Z",
     "iopub.status.busy": "2023-07-26T04:15:00.056071Z",
     "iopub.status.idle": "2023-07-26T04:15:01.545129Z",
     "shell.execute_reply": "2023-07-26T04:15:01.544445Z",
     "shell.execute_reply.started": "2023-07-26T04:15:00.056310Z"
    }
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM, GenerationConfig, pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "098e7d4e-dcbf-4c63-8d07-73e05e288317",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T04:15:01.546744Z",
     "iopub.status.busy": "2023-07-26T04:15:01.546493Z",
     "iopub.status.idle": "2023-07-26T04:15:02.766343Z",
     "shell.execute_reply": "2023-07-26T04:15:02.765513Z",
     "shell.execute_reply.started": "2023-07-26T04:15:01.546727Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0df199eb-3d18-48b9-a7d9-e187ab0e6a34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T04:15:02.768002Z",
     "iopub.status.busy": "2023-07-26T04:15:02.767689Z",
     "iopub.status.idle": "2023-07-26T04:15:02.771871Z",
     "shell.execute_reply": "2023-07-26T04:15:02.771085Z",
     "shell.execute_reply.started": "2023-07-26T04:15:02.767982Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import LlamaTokenizer\n",
    "import sentencepiece\n",
    "model = \"tiiuae/falcon-40b-instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6874c97b-97e9-47ec-ada4-9c2577a492a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T04:15:03.305447Z",
     "iopub.status.busy": "2023-07-26T04:15:03.304959Z",
     "iopub.status.idle": "2023-07-26T04:15:03.513084Z",
     "shell.execute_reply": "2023-07-26T04:15:03.512428Z",
     "shell.execute_reply.started": "2023-07-26T04:15:03.305425Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ac6380d-5379-4d9b-b977-f973152e3182",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T04:14:35.086867Z",
     "iopub.status.busy": "2023-07-26T04:14:35.086449Z",
     "iopub.status.idle": "2023-07-26T04:14:37.554991Z",
     "shell.execute_reply": "2023-07-26T04:14:37.554253Z",
     "shell.execute_reply.started": "2023-07-26T04:14:35.086846Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cpu:\n",
      "Collecting einops\n",
      "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
      "     |████████████████████████████████| 42 kB 3.7 MB/s             \n",
      "\u001b[?25hInstalling collected packages: einops\n",
      "Successfully installed einops-0.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip install einops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04b93ede-baca-4200-bf08-c734b80979aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T04:15:06.151846Z",
     "iopub.status.busy": "2023-07-26T04:15:06.151155Z",
     "iopub.status.idle": "2023-07-26T04:28:33.241715Z",
     "shell.execute_reply": "2023-07-26T04:28:33.241069Z",
     "shell.execute_reply.started": "2023-07-26T04:15:06.151826Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43a8248b90a442c381b15317b995aaa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)model.bin.index.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d939fdaee2d64afba237cb8f00a0867a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4284b12bf006482cb6191205b0bcea22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00001-of-00009.bin:   0%|          | 0.00/9.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1d001ce3c66425eaf9b3ae6c4c6c1f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00002-of-00009.bin:   0%|          | 0.00/9.51G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "695046b54db54dd1a14f17fe69c83d80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00003-of-00009.bin:   0%|          | 0.00/9.51G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af6917c0145b49a180b59864c9102f48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00004-of-00009.bin:   0%|          | 0.00/9.51G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb90017e181c4fd4b762d38cf364c806",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00005-of-00009.bin:   0%|          | 0.00/9.51G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05b077afe11749a5bd4b9ea90085696c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00006-of-00009.bin:   0%|          | 0.00/9.51G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "392efdc48d3f4aedbf28b81236ee5afa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00007-of-00009.bin:   0%|          | 0.00/9.51G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fba3569bb09f40c78ca4dcb3e1ebebcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00008-of-00009.bin:   0%|          | 0.00/9.51G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bf5a0a0b206448b930e90642d2cf546",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00009-of-00009.bin:   0%|          | 0.00/7.58G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15942f9a75d0407c88d9b77967b7dfd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af3f6029ed74409b8473f2b670b0deaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7be90899-ce84-449c-b9e4-47c9a85d3de9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T04:29:59.709536Z",
     "iopub.status.busy": "2023-07-26T04:29:59.708679Z",
     "iopub.status.idle": "2023-07-26T04:29:59.712720Z",
     "shell.execute_reply": "2023-07-26T04:29:59.712011Z",
     "shell.execute_reply.started": "2023-07-26T04:29:59.709514Z"
    }
   },
   "outputs": [],
   "source": [
    "local_llm = HuggingFacePipeline(pipeline=pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5ac4593-4938-4a3d-b94a-4eae28ce16b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T04:30:01.661513Z",
     "iopub.status.busy": "2023-07-26T04:30:01.660844Z",
     "iopub.status.idle": "2023-07-26T04:30:01.664716Z",
     "shell.execute_reply": "2023-07-26T04:30:01.663902Z",
     "shell.execute_reply.started": "2023-07-26T04:30:01.661494Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "202fc20b-0f02-4d29-98e9-c73f8462a13e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T04:30:03.144884Z",
     "iopub.status.busy": "2023-07-26T04:30:03.144222Z",
     "iopub.status.idle": "2023-07-26T04:30:03.148789Z",
     "shell.execute_reply": "2023-07-26T04:30:03.148213Z",
     "shell.execute_reply.started": "2023-07-26T04:30:03.144840Z"
    }
   },
   "outputs": [],
   "source": [
    "instr = \"\"\"\n",
    "Winning or victory means position=1.\n",
    "Victory margin means check position=1 and then check margin.\n",
    "JD(s) or JD(S) means party=Janata Dal (Secular).\n",
    "When asked for minimum or maximum respond with all possible choices that have the minimum or maximum value.\n",
    "Voter Turnout is calculated by dividing the number of votes by the number of voters.\n",
    "Use margin if query asks to use margin. \n",
    "Use votes if query asks to use votes.\n",
    "Largest means maximum.\n",
    "Smallest means minimum.\n",
    "Largest number of candidates means count(candidate_name) as num_candidates group by ac_name_y order by num_candidates.\n",
    "Less than x votes means votes<x.\n",
    "Victory margin over x means margin>x and position=1.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20c3e86f-fc87-4e38-a717-d63928d61278",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T04:30:06.471495Z",
     "iopub.status.busy": "2023-07-26T04:30:06.470866Z",
     "iopub.status.idle": "2023-07-26T04:30:06.474358Z",
     "shell.execute_reply": "2023-07-26T04:30:06.473552Z",
     "shell.execute_reply.started": "2023-07-26T04:30:06.471474Z"
    }
   },
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Write a SQL Query given the table name {Table} and columns as a list {Columns} for the given question : \n",
    "{question} using Instructions:\n",
    "{Ins}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b5824d1-9d37-4531-af8e-0786011df074",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T04:30:07.457303Z",
     "iopub.status.busy": "2023-07-26T04:30:07.456558Z",
     "iopub.status.idle": "2023-07-26T04:30:07.460983Z",
     "shell.execute_reply": "2023-07-26T04:30:07.460291Z",
     "shell.execute_reply.started": "2023-07-26T04:30:07.457260Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(template=template, input_variables=[\"Table\",\"question\",\"Columns\",\"Ins\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c06ab5c7-9b67-4c9a-bf66-7aab2b4ed987",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T04:30:09.378307Z",
     "iopub.status.busy": "2023-07-26T04:30:09.377324Z",
     "iopub.status.idle": "2023-07-26T04:30:09.381676Z",
     "shell.execute_reply": "2023-07-26T04:30:09.380890Z",
     "shell.execute_reply.started": "2023-07-26T04:30:09.378265Z"
    }
   },
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(prompt=prompt, llm=local_llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c101cfa-cba7-4881-adb2-bcbd91ad9171",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-26T04:43:28.771983Z",
     "iopub.status.idle": "2023-07-26T04:43:28.772332Z",
     "shell.execute_reply": "2023-07-26T04:43:28.772198Z",
     "shell.execute_reply.started": "2023-07-26T04:43:28.772184Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_llm_response(tble,question,cols,inst):\n",
    "    sequences = pipeline(\n",
    "        prompt.format(Table=tble, question=question, Columns=cols, Ins=inst)\n",
    "    max_length=400,\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "    for seq in sequences:\n",
    "        print(f\"Result: {seq['generated_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ebdee1-3226-4331-a45d-1354350b95ba",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-26T04:43:28.773501Z",
     "iopub.status.idle": "2023-07-26T04:43:28.773733Z",
     "shell.execute_reply": "2023-07-26T04:43:28.773629Z",
     "shell.execute_reply.started": "2023-07-26T04:43:28.773618Z"
    }
   },
   "outputs": [],
   "source": [
    "tble = \"eci_kr_2023\"\n",
    "cols = ['ac_no', 'ac_name_x', 'regions', 'caste', 'locality', 'district', 's_no', 'candidate_name', 'party', 'evm_votes', 'postal_votes', 'votes', 'vote_share', 'st_name', 'st_no', 'ac_name_y', 'constituency_code', 'position', 'total_votes', 'margin', 'margin_percent', 'vote_share_percent', 'margin_buckets_percent', 'margin_buckets_votes']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1119a598-7aa8-4c29-8b98-00ec645957b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T04:43:34.423208Z",
     "iopub.status.busy": "2023-07-26T04:43:34.422927Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Input length of input_ids is 377, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
     ]
    }
   ],
   "source": [
    "question=\"How many MLAs won with more than 1000 votes?\"\n",
    "get_llm_response(tble,question,cols,instr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d1edeb-97c1-4a82-ab3c-44502ca43d16",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-26T04:43:28.776261Z",
     "iopub.status.idle": "2023-07-26T04:43:28.776496Z",
     "shell.execute_reply": "2023-07-26T04:43:28.776386Z",
     "shell.execute_reply.started": "2023-07-26T04:43:28.776375Z"
    }
   },
   "outputs": [],
   "source": [
    "question=\"Count of MLAs won with more than fifty thousand votes\"\n",
    "get_llm_response(tble,question,cols,instr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4882a2-2a25-4b53-8d5b-307b29c8915f",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-26T04:43:28.777138Z",
     "iopub.status.idle": "2023-07-26T04:43:28.777553Z",
     "shell.execute_reply": "2023-07-26T04:43:28.777439Z",
     "shell.execute_reply.started": "2023-07-26T04:43:28.777426Z"
    }
   },
   "outputs": [],
   "source": [
    "question=\"Number of candidates fielded by the JD(S)?\"\n",
    "get_llm_response(tble,question,cols,instr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1711c0-7f64-4045-9a6b-a246ad0b7e0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
